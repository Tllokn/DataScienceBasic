{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "import time\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "#import cnn_p2 as cnn  \n",
    "import cnn_utils_solutions as cnn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "importlib.reload(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will implement the following CNN network from scratch\n",
    "- The following **optional** code is from the [CNN tutorial at PyTorch](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).  It illustrates how the network is specified in PyTorch, and counts the number of parameters.  You will have to install PyTorch for it to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This is OPTIONAL code.  It will not run unless\n",
    "# PyTorch is installed.\n",
    "#\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "def count_parameters(model):\n",
    "    total_params = 0\n",
    "    print(f\"The number of trainable params in each layer:\")\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        print('  ', name, f'{params:,d}')\n",
    "        total_params+=params\n",
    "    print(f\"Total trainable params: {total_params:,d}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Below are test cases to help you debug the Conv, MaxPool and Flatten\n",
    "- For HW5, you will also rely on other Operation Classes (VDot, Softmax, Log, etc) that you have implemented in HW4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class FailTestError(Exception):\n",
    "    pass\n",
    "\n",
    "input_tensor = cnn.InputValue(np.arange(4*4*2).reshape((4,4,2)))\n",
    "conv1 = cnn.InputValue(np.arange(3*3*2*4).reshape((3,3,2,4)))\n",
    "bias1 = cnn.InputValue(np.arange(4))\n",
    "v1 = cnn.InputValue(np.arange(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Conv\n",
    "x = cnn.Add(input_tensor, input_tensor)\n",
    "y = cnn.Conv(x, conv1, 1, 0)\n",
    "z = cnn.Add(y, bias1)\n",
    "for component in [x,y,z]:\n",
    "    component.forward()\n",
    "z.grad = np.ones_like(z.value)\n",
    "for component in [x, y, conv1, bias1]:\n",
    "    component.grad = 0\n",
    "for component in [z,y,x]:\n",
    "    component.backward()\n",
    "\n",
    "yvalue = np.array([[[17880., 18258., 18636., 19014.],\n",
    "                    [20328., 20778., 21228., 21678.]],\n",
    "\n",
    "                   [[27672., 28338., 29004., 29670.],\n",
    "                    [30120., 30858., 31596., 32334.]]])\n",
    "y_kernel_grad = np.array([[[[ 40.,  40.,  40.,  40.],\n",
    "                             [ 48.,  48.,  48.,  48.]],\n",
    "\n",
    "                            [[ 56.,  56.,  56.,  56.],\n",
    "                             [ 64.,  64.,  64.,  64.]],\n",
    "\n",
    "                            [[ 72.,  72.,  72.,  72.],\n",
    "                             [ 80.,  80.,  80.,  80.]]],\n",
    "\n",
    "\n",
    "                           [[[104., 104., 104., 104.],\n",
    "                             [112., 112., 112., 112.]],\n",
    "\n",
    "                            [[120., 120., 120., 120.],\n",
    "                             [128., 128., 128., 128.]],\n",
    "\n",
    "                            [[136., 136., 136., 136.],\n",
    "                             [144., 144., 144., 144.]]],\n",
    "\n",
    "\n",
    "                           [[[168., 168., 168., 168.],\n",
    "                             [176., 176., 176., 176.]],\n",
    "\n",
    "                            [[184., 184., 184., 184.],\n",
    "                             [192., 192., 192., 192.]],\n",
    "\n",
    "                            [[200., 200., 200., 200.],\n",
    "                             [208., 208., 208., 208.]]]])\n",
    "y_inputtensor_grad = np.array([[[  6.,  22.],\n",
    "                                [ 44.,  76.],\n",
    "                                [108., 140.],\n",
    "                                [ 70.,  86.]],\n",
    "\n",
    "                               [[108., 140.],\n",
    "                                [280., 344.],\n",
    "                                [408., 472.],\n",
    "                                [236., 268.]],\n",
    "\n",
    "                               [[300., 332.],\n",
    "                                [664., 728.],\n",
    "                                [792., 856.],\n",
    "                                [428., 460.]],\n",
    "\n",
    "                               [[198., 214.],\n",
    "                                [428., 460.],\n",
    "                                [492., 524.],\n",
    "                                [262., 278.]]])\n",
    "\n",
    "if not np.array_equal(y.value, yvalue):\n",
    "    raise FailTestError(\"The output of Conv is incorrect\")\n",
    "if not np.array_equal(y.kernel.grad, y_kernel_grad):\n",
    "    raise FailTestError(\"The gradient of kernel in Conv is incorrect\")\n",
    "if not np.array_equal(y.input_tensor.grad, y_inputtensor_grad):\n",
    "    raise FailTestError(\"The gradient of input_tensor in Conv is incorrect\")\n",
    "print(\"Passed test on Conv with default settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# For Full Credit: Conv with stride 2\n",
    "x = cnn.Add(input_tensor, input_tensor)\n",
    "y = cnn.Conv(x, conv1, 1, 1)\n",
    "z = cnn.Add(y, bias1)\n",
    "for component in [x,y,z]:\n",
    "    component.forward()\n",
    "z.grad = np.ones_like(z.value)\n",
    "for component in [x, y, conv1, bias1]:\n",
    "    component.grad = 0\n",
    "for component in [z,y,x]:\n",
    "    component.backward()\n",
    "\n",
    "yvalue = np.array([[[ 5248.,  5336.,  5424.,  5512.],\n",
    "                    [ 8608.,  8764.,  8920.,  9076.],\n",
    "                    [10816., 11020., 11224., 11428.],\n",
    "                    [ 7232.,  7384.,  7536.,  7688.]],\n",
    "\n",
    "                   [[11856., 12084., 12312., 12540.],\n",
    "                    [17880., 18258., 18636., 19014.],\n",
    "                    [20328., 20778., 21228., 21678.],\n",
    "                    [12912., 13236., 13560., 13884.]],\n",
    "\n",
    "                   [[19152., 19572., 19992., 20412.],\n",
    "                    [27672., 28338., 29004., 29670.],\n",
    "                    [30120., 30858., 31596., 32334.],\n",
    "                    [18672., 19188., 19704., 20220.]],\n",
    "\n",
    "                   [[ 9792., 10136., 10480., 10824.],\n",
    "                    [13312., 13852., 14392., 14932.],\n",
    "                    [14368., 14956., 15544., 16132.],\n",
    "                    [ 8192.,  8600.,  9008.,  9416.]]])\n",
    "y_kernel_grad = np.array([[[[180., 180., 180., 180.],\n",
    "                         [198., 198., 198., 198.]],\n",
    "\n",
    "                        [[264., 264., 264., 264.],\n",
    "                         [288., 288., 288., 288.]],\n",
    "\n",
    "                        [[216., 216., 216., 216.],\n",
    "                         [234., 234., 234., 234.]]],\n",
    "\n",
    "\n",
    "                       [[[336., 336., 336., 336.],\n",
    "                         [360., 360., 360., 360.]],\n",
    "\n",
    "                        [[480., 480., 480., 480.],\n",
    "                         [512., 512., 512., 512.]],\n",
    "\n",
    "                        [[384., 384., 384., 384.],\n",
    "                         [408., 408., 408., 408.]]],\n",
    "\n",
    "\n",
    "                       [[[324., 324., 324., 324.],\n",
    "                         [342., 342., 342., 342.]],\n",
    "\n",
    "                        [[456., 456., 456., 456.],\n",
    "                         [480., 480., 480., 480.]],\n",
    "\n",
    "                        [[360., 360., 360., 360.],\n",
    "                         [378., 378., 378., 378.]]]])\n",
    "y_inputtensor_grad = np.array([[[ 280.,  344.],\n",
    "                                [ 516.,  612.],\n",
    "                                [ 516.,  612.],\n",
    "                                [ 408.,  472.]],\n",
    "\n",
    "                               [[ 708.,  804.],\n",
    "                                [1206., 1350.],\n",
    "                                [1206., 1350.],\n",
    "                                [ 900.,  996.]],\n",
    "\n",
    "                               [[ 708.,  804.],\n",
    "                                [1206., 1350.],\n",
    "                                [1206., 1350.],\n",
    "                                [ 900.,  996.]],\n",
    "\n",
    "                               [[ 664.,  728.],\n",
    "                                [1092., 1188.],\n",
    "                                [1092., 1188.],\n",
    "                                [ 792.,  856.]]])\n",
    "\n",
    "if not np.array_equal(y.value, yvalue):\n",
    "    raise FailTestError(\"The output of Conv is incorrect\")\n",
    "if not np.array_equal(y.kernel.grad, y_kernel_grad):\n",
    "    raise FailTestError(\"The gradient of kernel in Conv is incorrect\")\n",
    "if not np.array_equal(y.input_tensor.grad, y_inputtensor_grad):\n",
    "    raise FailTestError(\"The gradient of input_tensor in Conv is incorrect\")\n",
    "print(\"Passed Test on Conv with non-zero padding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Full Credit: Conv with stride 2 and padding 1\n",
    "x = cnn.Add(input_tensor, input_tensor)\n",
    "y = cnn.Conv(x, conv1, 2, 1)\n",
    "z = cnn.Add(y, bias1)\n",
    "for component in [x,y,z]:\n",
    "    component.forward()\n",
    "z.grad = np.ones_like(z.value)\n",
    "for component in [x, y, conv1, bias1]:\n",
    "    component.grad = 0\n",
    "for component in [z,y,x]:\n",
    "    component.backward()\n",
    "\n",
    "yvalue = np.array([[[ 5248.,  5336.,  5424.,  5512.],\n",
    "                    [10816., 11020., 11224., 11428.]],\n",
    "\n",
    "                   [[19152., 19572., 19992., 20412.],\n",
    "                    [30120., 30858., 31596., 32334.]]])\n",
    "y_kernel_grad = np.array([[[[ 20.,  20.,  20.,  20.],\n",
    "                             [ 22.,  22.,  22.,  22.]],\n",
    "\n",
    "                            [[ 40.,  40.,  40.,  40.],\n",
    "                             [ 44.,  44.,  44.,  44.]],\n",
    "\n",
    "                            [[ 48.,  48.,  48.,  48.],\n",
    "                             [ 52.,  52.,  52.,  52.]]],\n",
    "\n",
    "\n",
    "                           [[[ 40.,  40.,  40.,  40.],\n",
    "                             [ 44.,  44.,  44.,  44.]],\n",
    "\n",
    "                            [[ 80.,  80.,  80.,  80.],\n",
    "                             [ 88.,  88.,  88.,  88.]],\n",
    "\n",
    "                            [[ 96.,  96.,  96.,  96.],\n",
    "                             [104., 104., 104., 104.]]],\n",
    "\n",
    "\n",
    "                           [[[ 72.,  72.,  72.,  72.],\n",
    "                             [ 76.,  76.,  76.,  76.]],\n",
    "\n",
    "                            [[144., 144., 144., 144.],\n",
    "                             [152., 152., 152., 152.]],\n",
    "\n",
    "                            [[160., 160., 160., 160.],\n",
    "                             [168., 168., 168., 168.]]]])\n",
    "y_inputtensor_grad = np.array([[[134., 150.],\n",
    "                                [268., 300.],\n",
    "                                [134., 150.],\n",
    "                                [166., 182.]],\n",
    "\n",
    "                               [[268., 300.],\n",
    "                                [536., 600.],\n",
    "                                [268., 300.],\n",
    "                                [332., 364.]],\n",
    "\n",
    "                               [[134., 150.],\n",
    "                                [268., 300.],\n",
    "                                [134., 150.],\n",
    "                                [166., 182.]],\n",
    "\n",
    "                               [[230., 246.],\n",
    "                                [460., 492.],\n",
    "                                [230., 246.],\n",
    "                                [262., 278.]]])\n",
    "\n",
    "if not np.array_equal(y.value, yvalue):\n",
    "    raise FailTestError(\"The output of Conv is incorrect\")\n",
    "if not np.array_equal(y.kernel.grad, y_kernel_grad):\n",
    "    raise FailTestError(\"The gradient of kernel in Conv is incorrect\")\n",
    "if not np.array_equal(y.input_tensor.grad, y_inputtensor_grad):\n",
    "    raise FailTestError(\"The gradient of input_tensor in Conv is incorrect\")\n",
    "print(\"Passed Test on Conv with stride 2 and padding 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MaxPool\n",
    "x = cnn.Add(input_tensor, input_tensor)\n",
    "y = cnn.Conv(x, conv1, 1, 1)\n",
    "z = cnn.Add(y, bias1)\n",
    "u = cnn.RELU(z)\n",
    "v = cnn.MaxPool(u, 2)\n",
    "for component in [x,y,z,u,v]:\n",
    "    component.forward()\n",
    "v.grad = np.ones_like(v.value)\n",
    "for component in [x,y,z,u, conv1, bias1]:\n",
    "    component.grad = 0\n",
    "for component in [v,u,z,y,x]:\n",
    "    component.backward()\n",
    "\n",
    "vvalue = np.array([[[17880., 18259., 18638., 19017.],\n",
    "                    [20328., 20779., 21230., 21681.]],\n",
    "                   [[27672., 28339., 29006., 29673.],\n",
    "                    [30120., 30859., 31598., 32337.]]])\n",
    "v_inputtensor_grad = np.array([[[0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.]],\n",
    "\n",
    "                               [[0., 0., 0., 0.],\n",
    "                                [1., 1., 1., 1.],\n",
    "                                [1., 1., 1., 1.],\n",
    "                                [0., 0., 0., 0.]],\n",
    "\n",
    "                               [[0., 0., 0., 0.],\n",
    "                                [1., 1., 1., 1.],\n",
    "                                [1., 1., 1., 1.],\n",
    "                                [0., 0., 0., 0.]],\n",
    "\n",
    "                               [[0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.]]])\n",
    "\n",
    "if not np.array_equal(v.value, vvalue):\n",
    "    raise FailTestError(\"The output of MaxPool is incorrect\")\n",
    "if not np.array_equal(v.input_tensor.grad, v_inputtensor_grad):\n",
    "    raise FailTestError(\"The gradient of input_tensor in MaxPool is incorrect\")\n",
    "print(\"Passed Test on MaxPool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Full Credit: Test MaxPool with non-default stride\n",
    "x = cnn.Add(input_tensor, input_tensor)\n",
    "y = cnn.Conv(x, conv1, 1, 1)\n",
    "z = cnn.Add(y, bias1)\n",
    "u = cnn.RELU(z)\n",
    "v = cnn.MaxPool(u, 2, stride=4)\n",
    "for component in [x,y,z,u,v]:\n",
    "    component.forward()\n",
    "v.grad = np.ones_like(v.value)\n",
    "for component in [x,y,z,u, conv1, bias1]:\n",
    "    component.grad = 0\n",
    "for component in [v,u,z,y,x]:\n",
    "    component.backward()\n",
    "\n",
    "vvalue = np.array([[[30120., 30859., 31598., 32337.]]])\n",
    "v_inputtensor_grad = np.array([[[0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.]],\n",
    "\n",
    "                               [[0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.]],\n",
    "\n",
    "                               [[0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [1., 1., 1., 1.],\n",
    "                                [0., 0., 0., 0.]],\n",
    "\n",
    "                               [[0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.],\n",
    "                                [0., 0., 0., 0.]]])\n",
    "\n",
    "if not np.array_equal(v.value, vvalue):\n",
    "    raise FailTestError(\"The output of MaxPool is incorrect\")\n",
    "if not np.array_equal(v.input_tensor.grad, v_inputtensor_grad):\n",
    "    raise FailTestError(\"The gradient of input_tensor in MaxPool is incorrect\")\n",
    "print(\"Passed Test on MaxPool with non-default stride\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test Flatten\n",
    "x = cnn.Add(input_tensor, input_tensor)\n",
    "y = cnn.Conv(x, conv1, 1, 1)\n",
    "z = cnn.Add(y, bias1)\n",
    "u = cnn.RELU(z)\n",
    "v = cnn.MaxPool(u, 2)\n",
    "w = cnn.Flatten(v)\n",
    "o = cnn.Mul(w, v1)\n",
    "for component in [x,y,z,u,v,w,o]:\n",
    "    component.forward()\n",
    "o.grad = np.ones_like(o.value)\n",
    "for component in [x,y,z,u,v,w,conv1, bias1]:\n",
    "    component.grad = 0\n",
    "for component in [o,w,v,u,z,y,x]:\n",
    "    component.backward()\n",
    "\n",
    "wvalue = np.array([17880., 18259., 18638., 19017., 20328., 20779., 21230., 21681.,\n",
    "       27672., 28339., 29006., 29673., 30120., 30859., 31598., 32337.])\n",
    "w_inputtensor_grad = np.array([[[ 0.,  1.,  2.,  3.],\n",
    "        [ 4.,  5.,  6.,  7.]],\n",
    "\n",
    "       [[ 8.,  9., 10., 11.],\n",
    "        [12., 13., 14., 15.]]])\n",
    "\n",
    "if not np.array_equal(w.value, wvalue):\n",
    "    raise FailTestError(\"The output of Flatten is incorrect\")\n",
    "if not np.array_equal(w.input_tensor.grad, w_inputtensor_grad):\n",
    "    raise FailTestError(\"The gradient of input_tensor in Flatten is incorrect\")\n",
    "print(\"Passed Test on Flatten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Applying to the CIFAR10 dataset\n",
    "- You can refer to https://www.cs.toronto.edu/~kriz/cifar.html for details\n",
    "- Labels 0 to 9 refer to the following --- 0:airplane, 1:automobile, 2:bird, 3:cat, 4:deer, 5:dog, 6:frog, 7:horse, 8:ship, 9:truck\n",
    "- We will only use a subsample of 10000 images with 1000 of each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "data = np.load('./cifar10_data/sub_data.npz')\n",
    "X = np.float32(data['imgs'])/255.\n",
    "# Reshape the valid image data to (idx, h, w, channel)\n",
    "X = X.reshape(10000, 32, 32, 3)\n",
    "y = np.float32(data['labels'])\n",
    "\n",
    "# for simplicity, let's focus on the first four classes\n",
    "# there are 4000 images in total\n",
    "sub_idx = np.where(y<=3)[0]\n",
    "X = X[sub_idx]\n",
    "y = y[sub_idx]\n",
    "\n",
    "# split in to train an test set\n",
    "train_x, test_x = X[:3000], X[3000:]\n",
    "train_y, test_y = y[:3000], y[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is what an image looks like\n",
    "print(train_y[0])  # 3:cat\n",
    "imgplot = plt.imshow(train_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging the fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cnn)  # important line so that the changes you made on cnn_p2.py will be reflected without restarting the kernel\n",
    "model = cnn.CNN(num_labels=4)\n",
    "\n",
    "# # Used to generate sample_params, don't uncomment the codes below\n",
    "# model.init_params_with_xavier()\n",
    "# params = model.get_param_dict()\n",
    "# with open(\"./cifar10_data/sample_params.pkl\", 'wb') as f:\n",
    "#     pickle.dump(params, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# You can use the provided sample weights for initialization to help debug\n",
    "with open(\"./cifar10_data/sample_params.pkl\", 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "model.set_params_by_dict(params)\n",
    "\n",
    "# You can use the first 2 samples to test if the gradients are correct\n",
    "X = train_x[:2]\n",
    "y = train_y[:2]\n",
    "\n",
    "# when calling fit, a computational graph will be built first, you should expect the exact lines printed\n",
    "model.fit(X, y, alpha=0.01, t=1)\n",
    "\n",
    "# # Used to generate sample_grad, don't uncomment the codes below\n",
    "# sample_grad = {}\n",
    "# for k in params.keys():\n",
    "#     sample_grad[k] = model.params[k].grad\n",
    "# with open(\"./cifar10_data/sample_grad.pkl\", 'wb') as f:\n",
    "#     pickle.dump(sample_grad, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load the sample gradient for debugging\n",
    "with open(\"./cifar10_data/sample_grad.pkl\", 'rb') as f:\n",
    "    sample_grad = pickle.load(f)\n",
    "    \n",
    "for k in params.keys():\n",
    "    if not np.array_equal(np.round(sample_grad[k], 3), np.round(model.params[k].grad, 3)):\n",
    "        raise FailTestError(f\"gradient of param {k} is incorrect\")\n",
    "print(\"Congrats! You have passed the test of your fit function, your CNN model should be good to go!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now train your CNN on the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnn)\n",
    "model = cnn.CNN(num_labels=4)\n",
    "model.init_params_with_xavier()\n",
    "# It could take as much as 1 hour to train\n",
    "model.fit(train_x, train_y, 0.01, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 10 epochs, you should be able to achieve an accuracy of over 60%, \n",
    "# which is quite good compared with 25% of random guess\n",
    "accy, loss = model.eval(test_x, test_y)\n",
    "print(\"Test accuracy = %.4f, loss = %.4f\" % (accy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
